## Notes

I went through all Coursera, Udacity courses on 2016-03-17. I double
checked on 2016-03-21; I added a few more. OCW doesn't have problem
sets like these do, and I don't think Edx does either.

The plan I set out below should cover enough AI stuff; if I want to go
further, I think it would be a matter of getting a job in that.

## Coursera

Probably would not bother with any of the others here after I did the
above. It just wouldn't feel that necessary.

**Completed/In Progress**

* Machine Learning
    * https://www.coursera.org/learn/machine-learning/home/info
    * Andrew Ng
    * This was quite good. A little light on the math sometimes, but
      good.
* Probabilistic Graphical Models
    * https://www.coursera.org/course/pgm
    * Daphne Koller
    * Very serious course with much deeper graphical models and
      techniques.
* **Neural Nets**
    * https://www.coursera.org/course/neuralnets
    * Geoff Hinton
    * Serious course.
    * Looks like it has info on RNN and convolutional NN. Hopfield
      nets and Boltzman machines. Belief nets. Autoencoders.
    * Covers a lot; kinda boring instruction. Problem sets mediocre.
* Mining Massive Datasets
    * https://www.coursera.org/course/mmds
    * Jeff Ullman
    * Very data mining focused. I see a lot of clustering and LSH
      stuff. Some decision trees.
    * I just read the textbook. Wouldn't have been interesting enough
      to really do on its own.

**Interesting**

* *Compilers* (Stanford)
* *Fundamentals of Electrical Engineering* (Rice)

**Not Very Interesting**

* Cluster Analysis in Data Mining (UIUC)
* Digital Signal Processing (EPFL)
* Discrete Optimization (Melbourne)
* Heterogeneous Parallel Programming (UIUC)
* Natural Langauge Processing
    * https://www.coursera.org/course/nlangp
    * Columbia NLP course. Seems pretty serious.
    * Not super pumped about this area right now.
* Robotics Courses (UPenn; this is not free)
* Text Retrieval and Search Engines (UIUC)

**Uninteresting**

* Computer Architecture (Princeton)
    * Don't feel like I could learn a lot.
* Intro to Databases (Stanford)
    * Don't feel like I could learn a lot. Read the book!
* Natural Language Processing
    * https://www.coursera.org/course/nlp/
    * NLP course by Manning at Stanford. But looks like no archive of
      the material.

## Udacity

**Interesting**

* **Artificial Intelligence for Robotics** (Thrun, Georgia Tech)
    * https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373
    * Thrun
    * Kalman filters, PID.
* **Deep Learning** (From Google)

**Uninteresting**

* Introduction to AI (Norvig/Thrun; prolly book is better?)
    * https://www.udacity.com/course/intro-to-artificial-intelligence--cs271
    * Peter Norvig Sebastian Thrun
    * Doesn't look super serious. CS188 probably enough.
* Introduction to Computer Vision (Georgia Tech)
* Intro to Machine Learning
    * https://www.udacity.com/course/intro-to-machine-learning--ud120
    * Looks kind of weak. Is taught by Thrun...
    * Probably no reason to take after Ng.
* ML Series
    * Machine Learning (Georgia Tech)
    * Machine Learning: Unsupervised Learning (Georgia Tech)
    * Machine Learning: Reinforcement Learning (Georgia Tech)
    * Just feel like this would duplicate stuff I learned elsewhere.

## EdX and Other

**Interesting**

* **CS188**
    * https://www.edx.org/course/artificial-intelligence-uc-berkeleyx-cs188-1x
    * Looks clearly based on the Norvig AI book. Looks like it has
      some reinforcement learning stuff.
    * Is pretty okay; nothing amazingly awesome, but fine.
* **Wasserman Statistical Machine Learning**
    * http://www.stat.cmu.edu/~larry/=sml/
    * CMU grad course.

**Kinda Interesting**

* Strang Lectures
    * http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/
    * Pretty good. Goes through all the major things I think you're
      supposed to know.
    * But I think I might do better just out of the book.

**Uninteresting**

* Convex Optimization (Stephen Boyd)
    * Doesn't seem to cover conjugate-gradient descent or quasi-newton
      methods?
    * Bah.
* http://cs231n.stanford.edu/
    * Convolutional NN for Visual Recognition.
    * But I have to imagine that Hinton is enough.
* https://www.edx.org/course/scalable-machine-learning-uc-berkeleyx-cs190-1x
    * Scalable Machine Learning
    * No big names.
    * Looks pretty meh. Mostly about Hadoop/Spark for large ML
      problems. Not very long.
* https://work.caltech.edu/telecourse.html
    * Learning From Data Caltech
    * Highly rated. Looks like it is broadly similar to Andrew Ng,
      though.
* https://www.edx.org/course/underactuated-robotics-mitx-6-832x-0
    * MIT course. Seems interesting.
    * But maybe I can think about it again later.
