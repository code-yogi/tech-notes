## Case Against Reality

* We don't perceive reality, that wouldn't be useful for evolution
  anyway.
* "Hard problem", btw, is how we get qualia from physical process.
    * Chalmers and Whitehead both believe there is a consciousness
      as a primordial feature of all things.
* Theorem: reality will never beat a function that sees no reality
  but tuned to fitness. I don't know the details of that theorem,
  but seems obvious.
* Not sure that this shows that reality is *worse*. But maybe it
  would be more complex/expensive?
* Article from Atlantic; not actually insightful.

## Aaronson Response to Penrose

* Also read Aaronson's response to Penrose.
* First, he says that many in AI would say that since we can
  replace neurons with circuits, which would act human, we would
  call it human. Thus consciousness.
* Aaronson says there is something we don't understand, but he
  doesn't think it has anything to do with qualia.
    * He says, how do we know that a robot wouldn't have a
      subjective experience?
    * I say that's possible, but then it's a truly incredible
      thing.
* He asks a bunch of hypotheticals that he thinks are hard to
  resolve for the AI people, none with qualia.
    * E.g., what if the simulation is really slow, with people
      passing around notes. Would consciousness arise there?
    * Can we fax people?
    * So Aaronson agrees there are questions. But he says the
      "burden" is on others to show in what way a brain couldn't
      be simulated on a TM.
* Says he respects Penrose because he tries to do that.
* Maintains physical Church-Turing thesis, which is really what
  Penrose is attacking.
* But Aaronson says: how does it help explain consciousness if the
  world is a hypercomputer. E.g., if there's an oracle for the
  halting problem, doesn't that seem just as robotic as the TM.
    * Given that, it does seem to make sense to put the burden on
      the hypercomputation people.
* Aaronson says there's more weirdness. We know how to copy computer
  programs. But you can't copy a human, not exactly, because of no
  cloning.
    * So a weird question. Maybe a program can be consciousness.
    * But *your* consciousness is not reproducible, if you obey
      no-cloning.
* He asks a free will style question: can I predict perfectly what you
  will do.
    * If it depends on your quantum state, the answer is no.
    * Well, not without collapsing your quantum state via measurement.
    * He says the implication of this is that our "free will" is maybe
      an amplification of the initial state of the universe, which is
      unknowable.
* He's saying: if consciousness isn't quantum, then I can prove no
  free will, because I can give a simulation of you. My clone's
  corresponding actions to yours show no free will.
    * If it is quantum, then I can't clone you to run the simulation.
    * So I can't prove it this way.
* He makes an observation: it's kinda nice to think that "murder" is
  about how you are destroying something irreplacable, which is very
  literally true if consciousness is inside the quantum state.
* Interesting response from Hameroff (anesthesiologist who is a
  cowriter with Penrose). He notes that by studying anesthetic gasses,
  you might understand how consciousness works, since anesthesia
  inhibits consciousness?x
* He makes a comment about how evolution isn't a perfect theory. He
  says: why would replicators exhibit survival behavior without reward
  or feelings? But that seems stupid: those are the replicators that
  would dominate. I think that's actually Boltzman's argument?
    * He notes that, in his theory, feelings and reward would have
      existed *before* life.
    * He later clarifies a bit: he says, without pleasure seeking,
      what drives evolution?
    * But that seems zany, it's a random walk, right?

Source:

http://www.scottaaronson.com/blog/?p=2756
