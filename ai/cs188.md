## Week 1: Lecture 1

* Suggests that two main takeaways from brain:
    * Can learn from experience (reinforcement).
    * Can learn from deductions about a model of the world (logic).
    * Claims that lack of complete database of all facts (or the
      ability to create this), means that systems will unavoidably
      have to deal with uncertainty.
    * Gives chess playing as an example where computers don't seem to
      think like humans, but are successful nonetheless.

## Week 2: Lecture 2 + Lecture 3

* Planning ahead by searching.
    * Look through sequence of actions.
    * Don't need to enumerate all action sequences, the agent will
      search for the best one in this context.
* DFS, BFS, IDDFS
* Dijkstra
* "Greedy" search. DFS based on heuristic.
* A-star.
    * Discussed admissability of a heuristic.
    * Used not just for path-finding, but also translation/parsing.
    * I guess any "sequential" process, like language.
* Coming up with heuristic through relaxation.
    * Tiles out of place.
    * Distance from tiles to be in place.
    * Taking max of heuristics.
    * Subproblems.
* Avoid repeated positions.
    * This means keeping a list of places you have been before.
    * That will tend to take more memory.
    * But prolly not a lot more, if you're doing A-star...
* Need to be careful. Got to make sure the cost of a path *keeps going
  up*.
    * Otherwise we might get to an intermediate node "the wrong way".
    * This property is *consistency*.
    * Which is the same as saying that the cost of an arc, plus the
      heuristic cost from the next vertex, most always be *greater*
      than the hueristic cost of this node.
    * Basically, we can never become more enthusiastic about a path.
* Might use an inadmissable heuristic if it is:
    * Faster to compute
    * Better approximates true cost, even if it overestimates
      sometimes.
